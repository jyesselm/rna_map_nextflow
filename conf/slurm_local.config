/*
 * SLURM + Local Hybrid Execution Profile
 * 
 * This profile submits the main workflow to SLURM, but uses local executor
 * for fast tasks to reduce job submission overhead. Best for workflows where
 * individual tasks complete quickly (< 5 minutes).
 * 
 * Usage:
 *   nextflow run main.nf -profile slurm_local --fasta ref.fasta --fastq1 reads.fastq
 */

process {
    executor = 'local'
    
    // Default resource limits (for local execution within SLURM job)
    cpus = { task.cpus ?: 4 }
    memory = { task.memory ?: '8 GB' }
    time = { task.time ?: '2h' }
    
    // No cluster options - we're running locally within a SLURM job
    clusterOptions = ""
    
    // Resource limits - use all CPUs allocated to the SLURM job
    // This allows parallel execution of tasks within the job
    maxForks = params.max_cpus ?: 16
    
    // Queue size - batch tasks to reduce overhead (0 = no limit, process as available)
    queueSize = 0
    
    // Poll interval - how often to check for new tasks (lower = faster response)
    pollInterval = '5s'
    
    // Process labels - adjust memory to match SLURM job allocation
    withLabel: 'process_low' {
        cpus = 2
        memory = '4 GB'
        time = '1h'
    }
    
    withLabel: 'process_medium' {
        cpus = 4
        memory = '8 GB'
        time = '2h'
    }
    
    // For high-memory processes, limit to available memory in SLURM job
    // Adjust based on your SLURM job's --mem setting
    withLabel: 'process_high' {
        cpus = { params.max_cpus ?: 4 }
        memory = { 
            // Use max_memory if specified, otherwise default to 16GB
            // This should match or be less than SLURM job memory
            def maxMem = params.max_memory ?: '16 GB'
            maxMem
        }
        time = { params.max_time ?: '4h' }
    }
    
    // Error handling
    maxRetries = 3
    errorStrategy = 'retry'
    
    // Cleanup
    cleanup = true
}

// Include base configuration
includeConfig "${baseDir}/conf/base.config"

