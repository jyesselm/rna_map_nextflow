/*
 * SLURM + Local Hybrid Execution Profile
 * 
 * This profile submits the main workflow to SLURM, but uses local executor
 * for fast tasks to reduce job submission overhead. Best for workflows where
 * individual tasks complete quickly (< 5 minutes).
 * 
 * Usage:
 *   nextflow run main.nf -profile slurm_local --fasta ref.fasta --fastq1 reads.fastq
 */

process {
    executor = 'local'
    
    // Default resource limits - most tasks only need 1 CPU and 2 GB
    // For local executor, tasks share the SLURM job resources
    cpus = { task.cpus ?: 1 }
    memory = { task.memory ?: '2 GB' }
    time = { task.time ?: '2h' }
    
    // No cluster options - we're running locally within a SLURM job
    clusterOptions = ""
    
    // Resource limits - use all CPUs allocated to the SLURM job
    // This allows parallel execution of tasks within the job
    maxForks = params.max_cpus ?: 16
    
    // Process labels - most tasks only need 1 CPU and 2 GB
    withLabel: 'process_low' {
        cpus = 1
        memory = '2 GB'
        time = '1h'
    }
    
    withLabel: 'process_medium' {
        cpus = 1
        memory = '2 GB'
        time = '2h'
    }
    
    // For high-memory processes, limit to available memory in SLURM job
    // Adjust based on your SLURM job's --mem setting
    withLabel: 'process_high' {
        cpus = { params.max_cpus ?: 4 }  // Some high tasks may need more CPUs
        memory = { 
            // Use max_memory if specified, otherwise default to 8GB
            // This should match or be less than SLURM job memory
            def maxMem = params.max_memory ?: '8 GB'
            maxMem
        }
        time = { params.max_time ?: '4h' }
    }
    
    // Error handling
    maxRetries = 3
    errorStrategy = 'retry'
}

// Include base configuration
includeConfig "${baseDir}/conf/base.config"

